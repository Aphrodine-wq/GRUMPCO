import type { NvidiaModelConfig } from "./types.js";

/**
 * Nemotron Text Models (NVIDIA)
 */
export const NEMOTRON_MODELS: NvidiaModelConfig[] = [
  {
    id: "nvidia/llama-3.1-nemotron-ultra-253b-v1",
    name: "Nemotron Ultra 253B",
    publisher: "NVIDIA",
    capabilities: ["chat", "code", "reasoning", "function-calling", "agentic"],
    contextWindow: 128_000,
    costPerTokenInput: 0.6 / 1_000_000,
    costPerTokenOutput: 0.6 / 1_000_000,
    description:
      "Superior inference efficiency with highest accuracy for scientific and complex reasoning",
    bestFor: ["scientific computing", "complex math", "enterprise coding"],
    parameters: "253B",
    supportsTools: true,
    supportsStreaming: true,
  },
  {
    id: "nvidia/llama-3.3-nemotron-super-49b-v1.5",
    name: "Nemotron Super 49B v1.5",
    publisher: "NVIDIA",
    capabilities: ["chat", "code", "reasoning", "function-calling", "agentic"],
    contextWindow: 128_000,
    costPerTokenInput: 0.2 / 1_000_000,
    costPerTokenOutput: 0.2 / 1_000_000,
    description:
      "High efficiency model with leading accuracy for reasoning and tool calling",
    bestFor: [
      "balanced performance",
      "cost-effective reasoning",
      "general tasks",
    ],
    parameters: "49B",
    supportsTools: true,
    supportsStreaming: true,
  },
  {
    id: "nvidia/llama-3.3-nemotron-49b-instruct",
    name: "Nemotron 49B",
    publisher: "NVIDIA",
    capabilities: ["chat", "code", "reasoning", "function-calling"],
    contextWindow: 128_000,
    costPerTokenInput: 0.18 / 1_000_000,
    costPerTokenOutput: 0.18 / 1_000_000,
    description: "Efficient model for reasoning and instruction following",
    bestFor: ["general tasks", "coding", "instruction following"],
    parameters: "49B",
    supportsTools: true,
    supportsStreaming: true,
  },
  {
    id: "nvidia/nvidia-nemotron-nano-9b-v2",
    name: "Nemotron Nano 9B v2",
    publisher: "NVIDIA",
    capabilities: ["chat", "reasoning", "agentic"],
    contextWindow: 128_000,
    costPerTokenInput: 0.015 / 1_000_000,
    costPerTokenOutput: 0.015 / 1_000_000,
    description: "High-efficiency LLM with hybrid Transformer-Mamba design",
    bestFor: ["edge reasoning", "mobile", "embedded systems"],
    parameters: "9B",
    supportsTools: true,
    supportsStreaming: true,
  },
  {
    id: "nvidia/nemotron-3-nano-30b-a3b",
    name: "Nemotron 3 Nano 30B A3B",
    publisher: "NVIDIA",
    capabilities: [
      "chat",
      "code",
      "reasoning",
      "function-calling",
      "long-context",
    ],
    contextWindow: 1_000_000,
    costPerTokenInput: 0.25 / 1_000_000,
    costPerTokenOutput: 0.25 / 1_000_000,
    description:
      "Open, efficient MoE model with 1M context - coding, reasoning, tool calling",
    bestFor: ["very long documents", "RAG", "coding with large context"],
    parameters: "30B (A3B active)",
    moE: true,
    supportsTools: true,
    supportsStreaming: true,
  },
];
