import type { NvidiaModelConfig } from './types.js';

/**
 * Qwen Models (Qwen/Alibaba)
 */
export const QWEN_MODELS: NvidiaModelConfig[] = [
  {
    id: 'qwen/qwen3-coder-480b-a35b-instruct',
    name: 'Qwen3 Coder 480B A35B',
    publisher: 'Qwen',
    capabilities: ['chat', 'code', 'agentic', 'long-context'],
    contextWindow: 256_000,
    costPerTokenInput: 0.8 / 1_000_000,
    costPerTokenOutput: 0.8 / 1_000_000,
    description: 'Excels in agentic coding and browser use with 256K context',
    bestFor: ['agentic coding', 'browser automation', 'large codebase analysis'],
    parameters: '480B (35B active)',
    moE: true,
    supportsTools: true,
    supportsStreaming: true,
  },
  {
    id: 'qwen/qwen3-235b-a22b',
    name: 'Qwen3 235B A22B',
    publisher: 'Qwen',
    capabilities: ['chat', 'reasoning', 'multilingual', 'function-calling'],
    contextWindow: 128_000,
    costPerTokenInput: 0.5 / 1_000_000,
    costPerTokenOutput: 0.5 / 1_000_000,
    description: 'Advanced reasoning MoE model for multilingual tasks',
    bestFor: ['multilingual chat', 'reasoning', 'instruction following'],
    parameters: '235B (22B active)',
    moE: true,
    supportsTools: true,
    supportsStreaming: true,
  },
  {
    id: 'qwen/qwen3-next-80b-a3b-instruct',
    name: 'Qwen3 Next 80B A3B',
    publisher: 'Qwen',
    capabilities: ['chat', 'agentic', 'text-generation', 'function-calling'],
    contextWindow: 128_000,
    costPerTokenInput: 0.25 / 1_000_000,
    costPerTokenOutput: 0.25 / 1_000_000,
    description: 'Hybrid attention with sparse MoE for ultra-long context AI',
    bestFor: ['general chat', 'agent workflows', 'long-context tasks'],
    parameters: '80B (3B active)',
    moE: true,
    supportsTools: true,
    supportsStreaming: true,
  },
  {
    id: 'qwen/qwen3-next-80b-a3b-thinking',
    name: 'Qwen3 Next 80B A3B Thinking',
    publisher: 'Qwen',
    capabilities: ['chat', 'reasoning', 'text-generation'],
    contextWindow: 128_000,
    costPerTokenInput: 0.3 / 1_000_000,
    costPerTokenOutput: 0.3 / 1_000_000,
    description: '80B parameter AI model with hybrid reasoning supporting 119 languages',
    bestFor: ['multilingual reasoning', 'complex tasks', 'global applications'],
    parameters: '80B (3B active)',
    moE: true,
    supportsTools: true,
    supportsStreaming: true,
    languages: ['119 languages supported'],
  },
  {
    id: 'qwen/qwq-32b',
    name: 'QWQ 32B',
    publisher: 'Qwen',
    capabilities: ['chat', 'code', 'reasoning', 'math'],
    contextWindow: 32_000,
    costPerTokenInput: 0.1 / 1_000_000,
    costPerTokenOutput: 0.1 / 1_000_000,
    description: 'Powerful reasoning model capable of thinking and reasoning',
    bestFor: ['mathematical reasoning', 'complex problem solving', 'coding'],
    parameters: '32B',
    supportsTools: false,
    supportsStreaming: true,
  },
  {
    id: 'qwen/qwen2.5-coder-32b-instruct',
    name: 'Qwen2.5 Coder 32B',
    publisher: 'Qwen',
    capabilities: ['chat', 'code', 'text-generation'],
    contextWindow: 128_000,
    costPerTokenInput: 0.15 / 1_000_000,
    costPerTokenOutput: 0.15 / 1_000_000,
    description: 'Advanced LLM for code generation and fixing across popular languages',
    bestFor: ['code generation', 'code repair', 'software development'],
    parameters: '32B',
    supportsTools: true,
    supportsStreaming: true,
  },
];
