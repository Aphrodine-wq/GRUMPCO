name: Performance Benchmarks

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    # Run benchmarks weekly on Monday at 00:00 UTC
    - cron: '0 0 * * 1'

env:
  CARGO_TERM_COLOR: always

jobs:
  benchmark-rust:
    name: Benchmark Rust Intent Compiler
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
          override: true
      
      - name: Cache Rust dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            intent-compiler/target/
          key: ${{ runner.os }}-cargo-bench-${{ hashFiles('intent-compiler/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-bench-
      
      - name: Run benchmarks
        working-directory: intent-compiler
        run: cargo bench --bench parser_bench
      
      - name: Store benchmark results
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: Rust Intent Compiler Benchmarks
          tool: 'cargo'
          output-file-path: intent-compiler/target/criterion/report/index.html
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true

  benchmark-build:
    name: Benchmark Build Times
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install hyperfine
        run: |
          wget https://github.com/sharkdp/hyperfine/releases/download/v1.18.0/hyperfine_1.18.0_amd64.deb
          sudo dpkg -i hyperfine_1.18.0_amd64.deb
      
      - name: Install backend dependencies
        working-directory: backend
        run: npm ci
      
      - name: Benchmark SWC vs TSC
        working-directory: backend
        run: |
          echo "## Build Performance" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          hyperfine --warmup 1 --runs 3 \
            --export-markdown build-bench.md \
            'npm run build' \
            'npm run build:tsc'
          cat build-bench.md >> $GITHUB_STEP_SUMMARY
      
      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: build-benchmarks
          path: backend/build-bench.md

  benchmark-api:
    name: Benchmark API Performance
    runs-on: ubuntu-latest
    services:
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install dependencies
        working-directory: backend
        run: npm ci
      
      - name: Build backend
        working-directory: backend
        run: npm run build
      
      - name: Start backend
        working-directory: backend
        run: |
          npm start &
          sleep 10
        env:
          NODE_ENV: production
          REDIS_HOST: localhost
          REDIS_PORT: 6379
      
      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6
      
      - name: Run load tests
        working-directory: backend
        run: k6 run tests/load/k6-scenarios.js --out json=k6-results.json
      
      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: api-benchmarks
          path: backend/k6-results.json
      
      - name: Upload k6 summary
        uses: actions/upload-artifact@v4
        with:
          name: api-benchmark-summary
          path: backend/k6-summary.json

  performance-regression:
    name: Check Performance Regression
    runs-on: ubuntu-latest
    needs: [benchmark-rust, benchmark-build, benchmark-api]
    steps:
      - uses: actions/checkout@v4
      
      - name: Download benchmark results
        uses: actions/download-artifact@v4
        with:
          name: build-benchmarks
      
      - name: Download k6 summary
        uses: actions/download-artifact@v4
        with:
          name: api-benchmark-summary
          path: api-benchmark-summary
      
      - name: Check for regressions
        run: |
          echo "## Performance Regression Check" >> $GITHUB_STEP_SUMMARY
          echo "Checking for performance regressions..." >> $GITHUB_STEP_SUMMARY
          K6_SUMMARY="api-benchmark-summary/k6-summary.json"
          [ -f "api-benchmark-summary/backend/k6-summary.json" ] && K6_SUMMARY="api-benchmark-summary/backend/k6-summary.json"
          if [ ! -f "$K6_SUMMARY" ]; then
            echo "❌ k6 summary missing" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
          P95_MS=$(node -e "
            const d = require('./'"$K6_SUMMARY"'');
            const m = d.metrics && d.metrics['http_req_duration'];
            const v = m && m.values && (m.values['p(95)'] ?? m.values['p95']);
            if (v == null) process.exit(2);
            console.log(Math.round(v));
          " 2>/dev/null) || true
          if [ -z "$P95_MS" ] || [ "$P95_MS" = "null" ]; then
            echo "⚠️ Could not extract p95; skipping threshold check" >> $GITHUB_STEP_SUMMARY
          else
            echo "http_req_duration p95: ${P95_MS}ms" >> $GITHUB_STEP_SUMMARY
            BASELINE="${K6_P95_BASELINE_MS:-5000}"
            if [ "$P95_MS" -gt "$BASELINE" ]; then
              echo "❌ Regression: p95 ${P95_MS}ms exceeds baseline ${BASELINE}ms" >> $GITHUB_STEP_SUMMARY
              exit 1
            fi
            echo "✅ p95 within baseline ${BASELINE}ms" >> $GITHUB_STEP_SUMMARY
          fi
          echo "✅ No significant regressions detected" >> $GITHUB_STEP_SUMMARY
